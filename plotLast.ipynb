{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "fn = \"datahidden/shpllama1b/SHPLlama-3.2-1B\"\n",
    "with open(fn, 'rb') as f:\n",
    "    (chosen_features_list, rejected_features_list, chosen_features_list_eval, rejected_features_list_eval) = pickle.load(f)\n",
    "\n",
    "chosen_features_list = chosen_features_list[:999]\n",
    "rejected_features_list = rejected_features_list[:999]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of chosen_features_list: 807\n",
      "chosen_features.shape: torch.Size([12903, 2048])\n",
      "rejected_features.shape: torch.Size([12903, 2048])\n",
      "length of chosen_features_list_eval: 43\n",
      "chosen_features_eval.shape: torch.Size([682, 2048])\n",
      "rejected_features_eval.shape: torch.Size([682, 2048])\n"
     ]
    }
   ],
   "source": [
    "print(f'length of chosen_features_list: {len(chosen_features_list)}')\n",
    "chosen_features = torch.cat(chosen_features_list, dim=0).float()\n",
    "rejected_features = torch.cat(rejected_features_list, dim=0).float()\n",
    "print(f'chosen_features.shape: {chosen_features.shape}')\n",
    "print(f'rejected_features.shape: {rejected_features.shape}')\n",
    "\n",
    "print(f'length of chosen_features_list_eval: {len(chosen_features_list_eval)}')\n",
    "chosen_features_eval = torch.cat(chosen_features_list_eval, dim=0).float()\n",
    "rejected_features_eval = torch.cat(rejected_features_list_eval, dim=0).float()\n",
    "print(f'chosen_features_eval.shape: {chosen_features_eval.shape}')\n",
    "print(f'rejected_features_eval.shape: {rejected_features_eval.shape}')\n",
    "\n",
    "n_samples = chosen_features.shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diff_features.shape: torch.Size([12903, 2048])\n",
      "diff_features_eval.shape: torch.Size([682, 2048])\n"
     ]
    }
   ],
   "source": [
    "diff_features = chosen_features - rejected_features\n",
    "print(f'diff_features.shape: {diff_features.shape}')\n",
    "\n",
    "diff_features_eval = chosen_features_eval - rejected_features_eval\n",
    "print(f'diff_features_eval.shape: {diff_features_eval.shape}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Define a neural network with no hidden layer\n",
    "class NeuralNetworkNoHidden(torch.nn.Module):\n",
    "    def __init__(self, input_size, output_size=1):\n",
    "        super(NeuralNetworkNoHidden, self).__init__()\n",
    "        self.outputlayer = torch.nn.Linear(input_size, output_size, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        r = self.outputlayer(x)\n",
    "        return r\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "def l1_2_norm(weight_matrix):\n",
    "    row_l2_norms = torch.norm(weight_matrix, p=2, dim=1)\n",
    "    l1_2 = torch.sum(row_l2_norms)\n",
    "    return l1_2\n",
    "\n",
    "def train_neural_network_no_hidden(model, optimizer, scheduler, diff,  beta, steps=1000, seed=0):\n",
    "    n, d = diff.shape\n",
    "    loss_history = []\n",
    "    torch.manual_seed(seed)\n",
    "    for step in range(int(steps)):\n",
    "        optimizer.zero_grad()\n",
    "        output = model(diff)\n",
    "        loss = - F.logsigmoid(output).sum() / n\n",
    "        loss += beta * model.outputlayer.weight.norm(1)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        loss_history.append(loss.item())\n",
    "        if step % 200 == 0:\n",
    "            print(f\"Step {step}, Loss: {loss.item()}\")\n",
    "    acc = (model(diff) > 0).float().mean()\n",
    "    return model, acc, loss_history\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training no hidden layer model with beta=0, n=200, seed=0\n",
      "Step 0, Loss: 0.6999874711036682\n",
      "Step 200, Loss: 0.12409786134958267\n",
      "Step 400, Loss: 0.07933369278907776\n",
      "Step 600, Loss: 0.06745956093072891\n",
      "Step 800, Loss: 0.06258139759302139\n",
      "Step 1000, Loss: 0.06013993173837662\n",
      "Step 1200, Loss: 0.05880219489336014\n",
      "Step 1400, Loss: 0.05805892497301102\n",
      "Step 1600, Loss: 0.057677533477544785\n",
      "Step 1800, Loss: 0.057527922093868256\n",
      "Training no hidden layer model with beta=0.035355339059327376, n=200, seed=0\n",
      "Step 0, Loss: 1.685624599456787\n",
      "Step 200, Loss: 0.6043628454208374\n",
      "Step 400, Loss: 0.5955451130867004\n",
      "Step 600, Loss: 0.5918502807617188\n",
      "Step 800, Loss: 0.5889717936515808\n",
      "Step 1000, Loss: 0.5870755910873413\n",
      "Step 1200, Loss: 0.5853759050369263\n",
      "Step 1400, Loss: 0.583943247795105\n",
      "Step 1600, Loss: 0.5829010009765625\n",
      "Step 1800, Loss: 0.582248330116272\n",
      "Training no hidden layer model with beta=0, n=200, seed=1\n",
      "Step 0, Loss: 0.704757034778595\n",
      "Step 200, Loss: 0.13834014534950256\n",
      "Step 400, Loss: 0.09539301693439484\n",
      "Step 600, Loss: 0.08406829833984375\n",
      "Step 800, Loss: 0.07941871136426926\n",
      "Step 1000, Loss: 0.07709160447120667\n",
      "Step 1200, Loss: 0.07581639289855957\n",
      "Step 1400, Loss: 0.07510779798030853\n",
      "Step 1600, Loss: 0.07474417239427567\n",
      "Step 1800, Loss: 0.07460153102874756\n",
      "Training no hidden layer model with beta=0.035355339059327376, n=200, seed=1\n",
      "Step 0, Loss: 1.572249412536621\n",
      "Step 200, Loss: 0.6217930316925049\n",
      "Step 400, Loss: 0.6153497099876404\n",
      "Step 600, Loss: 0.6119066476821899\n",
      "Step 800, Loss: 0.609420657157898\n",
      "Step 1000, Loss: 0.6074497103691101\n",
      "Step 1200, Loss: 0.6057528257369995\n",
      "Step 1400, Loss: 0.6044513583183289\n",
      "Step 1600, Loss: 0.6034727096557617\n",
      "Step 1800, Loss: 0.60284823179245\n",
      "Training no hidden layer model with beta=0, n=200, seed=2\n",
      "Step 0, Loss: 0.8533003330230713\n",
      "Step 200, Loss: 0.12247085571289062\n",
      "Step 400, Loss: 0.06647712737321854\n",
      "Step 600, Loss: 0.05119755491614342\n",
      "Step 800, Loss: 0.04488999396562576\n",
      "Step 1000, Loss: 0.041730232536792755\n",
      "Step 1200, Loss: 0.03999888896942139\n",
      "Step 1400, Loss: 0.03903711959719658\n",
      "Step 1600, Loss: 0.038543738424777985\n",
      "Step 1800, Loss: 0.03835025429725647\n",
      "Training no hidden layer model with beta=0.035355339059327376, n=200, seed=2\n",
      "Step 0, Loss: 1.508657455444336\n",
      "Step 200, Loss: 0.6046583652496338\n",
      "Step 400, Loss: 0.5990231037139893\n",
      "Step 600, Loss: 0.596129298210144\n",
      "Step 800, Loss: 0.594291627407074\n",
      "Step 1000, Loss: 0.5925112962722778\n",
      "Step 1200, Loss: 0.5912032127380371\n",
      "Step 1400, Loss: 0.5899613499641418\n",
      "Step 1600, Loss: 0.5890187621116638\n",
      "Step 1800, Loss: 0.5884180068969727\n",
      "Training no hidden layer model with beta=0, n=200, seed=3\n",
      "Step 0, Loss: 0.7698634266853333\n",
      "Step 200, Loss: 0.13945044577121735\n",
      "Step 400, Loss: 0.06393790245056152\n",
      "Step 600, Loss: 0.042327430099248886\n",
      "Step 800, Loss: 0.03334087133407593\n",
      "Step 1000, Loss: 0.028834721073508263\n",
      "Step 1200, Loss: 0.0263664573431015\n",
      "Step 1400, Loss: 0.024996068328619003\n",
      "Step 1600, Loss: 0.024293415248394012\n",
      "Step 1800, Loss: 0.024017974734306335\n",
      "Training no hidden layer model with beta=0.035355339059327376, n=200, seed=3\n",
      "Step 0, Loss: 1.513040542602539\n",
      "Step 200, Loss: 0.6491659283638\n",
      "Step 400, Loss: 0.6444414854049683\n",
      "Step 600, Loss: 0.6428243517875671\n",
      "Step 800, Loss: 0.6417015790939331\n",
      "Step 1000, Loss: 0.6404157876968384\n",
      "Step 1200, Loss: 0.639233410358429\n",
      "Step 1400, Loss: 0.638177752494812\n",
      "Step 1600, Loss: 0.6372534036636353\n",
      "Step 1800, Loss: 0.636672854423523\n",
      "Training no hidden layer model with beta=0, n=200, seed=4\n",
      "Step 0, Loss: 0.8158994913101196\n",
      "Step 200, Loss: 0.14103105664253235\n",
      "Step 400, Loss: 0.0779137909412384\n",
      "Step 600, Loss: 0.06064150109887123\n",
      "Step 800, Loss: 0.05352352187037468\n",
      "Step 1000, Loss: 0.04996249079704285\n",
      "Step 1200, Loss: 0.04801301285624504\n",
      "Step 1400, Loss: 0.0469307117164135\n",
      "Step 1600, Loss: 0.04637570306658745\n",
      "Step 1800, Loss: 0.04615810140967369\n",
      "Training no hidden layer model with beta=0.035355339059327376, n=200, seed=4\n",
      "Step 0, Loss: 1.819942593574524\n",
      "Step 200, Loss: 0.6422657370567322\n",
      "Step 400, Loss: 0.6339841485023499\n",
      "Step 600, Loss: 0.6305603384971619\n",
      "Step 800, Loss: 0.6283160448074341\n",
      "Step 1000, Loss: 0.6263482570648193\n",
      "Step 1200, Loss: 0.6247498989105225\n",
      "Step 1400, Loss: 0.6234825849533081\n",
      "Step 1600, Loss: 0.6224851012229919\n",
      "Step 1800, Loss: 0.6218957901000977\n",
      "Training no hidden layer model with beta=0, n=400, seed=0\n",
      "Step 0, Loss: 0.6873462796211243\n",
      "Step 200, Loss: 0.20204098522663116\n",
      "Step 400, Loss: 0.11564910411834717\n",
      "Step 600, Loss: 0.08763834834098816\n",
      "Step 800, Loss: 0.07552292943000793\n",
      "Step 1000, Loss: 0.06935320794582367\n",
      "Step 1200, Loss: 0.06595005095005035\n",
      "Step 1400, Loss: 0.06405440717935562\n",
      "Step 1600, Loss: 0.06308113038539886\n",
      "Step 1800, Loss: 0.06269952654838562\n",
      "Training no hidden layer model with beta=0.025, n=400, seed=0\n",
      "Step 0, Loss: 1.442279577255249\n",
      "Step 200, Loss: 0.6093956232070923\n",
      "Step 400, Loss: 0.6000791788101196\n",
      "Step 600, Loss: 0.596411943435669\n",
      "Step 800, Loss: 0.5939469337463379\n",
      "Step 1000, Loss: 0.5921280384063721\n",
      "Step 1200, Loss: 0.5906643867492676\n",
      "Step 1400, Loss: 0.589603841304779\n",
      "Step 1600, Loss: 0.5888320803642273\n",
      "Step 1800, Loss: 0.5883749127388\n",
      "Training no hidden layer model with beta=0, n=400, seed=1\n",
      "Step 0, Loss: 0.7042925953865051\n",
      "Step 200, Loss: 0.24049046635627747\n",
      "Step 400, Loss: 0.14301343262195587\n",
      "Step 600, Loss: 0.1084936112165451\n",
      "Step 800, Loss: 0.09321008622646332\n",
      "Step 1000, Loss: 0.08537411689758301\n",
      "Step 1200, Loss: 0.0810433179140091\n",
      "Step 1400, Loss: 0.07863003760576248\n",
      "Step 1600, Loss: 0.07739121466875076\n",
      "Step 1800, Loss: 0.07690571248531342\n",
      "Training no hidden layer model with beta=0.025, n=400, seed=1\n",
      "Step 0, Loss: 1.3349047899246216\n",
      "Step 200, Loss: 0.6266177296638489\n",
      "Step 400, Loss: 0.6212338805198669\n",
      "Step 600, Loss: 0.6192905902862549\n",
      "Step 800, Loss: 0.6178365349769592\n",
      "Step 1000, Loss: 0.6168175339698792\n",
      "Step 1200, Loss: 0.6158422827720642\n",
      "Step 1400, Loss: 0.6149458289146423\n",
      "Step 1600, Loss: 0.6143115758895874\n",
      "Step 1800, Loss: 0.6139068603515625\n",
      "Training no hidden layer model with beta=0, n=400, seed=2\n",
      "Step 0, Loss: 0.8438927531242371\n",
      "Step 200, Loss: 0.23709069192409515\n",
      "Step 400, Loss: 0.13489249348640442\n",
      "Step 600, Loss: 0.09748534858226776\n",
      "Step 800, Loss: 0.08053123205900192\n",
      "Step 1000, Loss: 0.07173695415258408\n",
      "Step 1200, Loss: 0.06684742122888565\n",
      "Step 1400, Loss: 0.06411414593458176\n",
      "Step 1600, Loss: 0.06270882487297058\n",
      "Step 1800, Loss: 0.062157705426216125\n",
      "Training no hidden layer model with beta=0.025, n=400, seed=2\n",
      "Step 0, Loss: 1.2632126808166504\n",
      "Step 200, Loss: 0.6301676630973816\n",
      "Step 400, Loss: 0.6244502067565918\n",
      "Step 600, Loss: 0.622638463973999\n",
      "Step 800, Loss: 0.6217235922813416\n",
      "Step 1000, Loss: 0.620922327041626\n",
      "Step 1200, Loss: 0.6200275421142578\n",
      "Step 1400, Loss: 0.6192633509635925\n",
      "Step 1600, Loss: 0.6186956167221069\n",
      "Step 1800, Loss: 0.6183226704597473\n",
      "Training no hidden layer model with beta=0, n=400, seed=3\n",
      "Step 0, Loss: 0.7538870573043823\n",
      "Step 200, Loss: 0.2682591378688812\n",
      "Step 400, Loss: 0.15168397128582\n",
      "Step 600, Loss: 0.10658107697963715\n",
      "Step 800, Loss: 0.08587026596069336\n",
      "Step 1000, Loss: 0.07508773356676102\n",
      "Step 1200, Loss: 0.06908635795116425\n",
      "Step 1400, Loss: 0.06573085486888885\n",
      "Step 1600, Loss: 0.0640057623386383\n",
      "Step 1800, Loss: 0.06332940608263016\n",
      "Training no hidden layer model with beta=0.025, n=400, seed=3\n",
      "Step 0, Loss: 1.2737526893615723\n",
      "Step 200, Loss: 0.6573143601417542\n",
      "Step 400, Loss: 0.6507336497306824\n",
      "Step 600, Loss: 0.648567795753479\n",
      "Step 800, Loss: 0.6472692489624023\n",
      "Step 1000, Loss: 0.6462661027908325\n",
      "Step 1200, Loss: 0.6452756524085999\n",
      "Step 1400, Loss: 0.6445183157920837\n",
      "Step 1600, Loss: 0.6438846588134766\n",
      "Step 1800, Loss: 0.6434850096702576\n",
      "Training no hidden layer model with beta=0, n=400, seed=4\n",
      "Step 0, Loss: 0.753669261932373\n",
      "Step 200, Loss: 0.2209453582763672\n",
      "Step 400, Loss: 0.12154542654752731\n",
      "Step 600, Loss: 0.08787662535905838\n",
      "Step 800, Loss: 0.07310902327299118\n",
      "Step 1000, Loss: 0.06554579734802246\n",
      "Step 1200, Loss: 0.06136304885149002\n",
      "Step 1400, Loss: 0.05903023108839989\n",
      "Step 1600, Loss: 0.05783184990286827\n",
      "Step 1800, Loss: 0.05736194923520088\n",
      "Training no hidden layer model with beta=0.025, n=400, seed=4\n",
      "Step 0, Loss: 1.6453418731689453\n",
      "Step 200, Loss: 0.6229363679885864\n",
      "Step 400, Loss: 0.6141701340675354\n",
      "Step 600, Loss: 0.6118844747543335\n",
      "Step 800, Loss: 0.6106449961662292\n",
      "Step 1000, Loss: 0.6097066402435303\n",
      "Step 1200, Loss: 0.6089130640029907\n",
      "Step 1400, Loss: 0.6080767512321472\n",
      "Step 1600, Loss: 0.6074857115745544\n",
      "Step 1800, Loss: 0.6071168184280396\n",
      "Training no hidden layer model with beta=0, n=800, seed=0\n",
      "Step 0, Loss: 0.6987183094024658\n",
      "Step 200, Loss: 0.3218388557434082\n",
      "Step 400, Loss: 0.21149036288261414\n",
      "Step 600, Loss: 0.15691614151000977\n",
      "Step 800, Loss: 0.12758712470531464\n",
      "Step 1000, Loss: 0.11093232780694962\n",
      "Step 1200, Loss: 0.10121005773544312\n",
      "Step 1400, Loss: 0.09563035517930984\n",
      "Step 1600, Loss: 0.09272307902574539\n",
      "Step 1800, Loss: 0.09157706797122955\n",
      "Training no hidden layer model with beta=0.017677669529663688, n=800, seed=0\n",
      "Step 0, Loss: 1.2681007385253906\n",
      "Step 200, Loss: 0.6197211742401123\n",
      "Step 400, Loss: 0.6114147305488586\n",
      "Step 600, Loss: 0.6094846725463867\n",
      "Step 800, Loss: 0.6082838177680969\n",
      "Step 1000, Loss: 0.6073430180549622\n",
      "Step 1200, Loss: 0.6065945625305176\n",
      "Step 1400, Loss: 0.605975866317749\n",
      "Step 1600, Loss: 0.6055217385292053\n",
      "Step 1800, Loss: 0.6052341461181641\n",
      "Training no hidden layer model with beta=0, n=800, seed=1\n",
      "Step 0, Loss: 0.7030661106109619\n",
      "Step 200, Loss: 0.34368064999580383\n",
      "Step 400, Loss: 0.2320081889629364\n",
      "Step 600, Loss: 0.1747128665447235\n",
      "Step 800, Loss: 0.14320074021816254\n",
      "Step 1000, Loss: 0.1250644326210022\n",
      "Step 1200, Loss: 0.1143975630402565\n",
      "Step 1400, Loss: 0.10825086385011673\n",
      "Step 1600, Loss: 0.10504192858934402\n",
      "Step 1800, Loss: 0.10377629846334457\n",
      "Training no hidden layer model with beta=0.017677669529663688, n=800, seed=1\n",
      "Step 0, Loss: 1.1726256608963013\n",
      "Step 200, Loss: 0.6236510276794434\n",
      "Step 400, Loss: 0.6171847581863403\n",
      "Step 600, Loss: 0.6156758069992065\n",
      "Step 800, Loss: 0.6149153113365173\n",
      "Step 1000, Loss: 0.6142613291740417\n",
      "Step 1200, Loss: 0.6136683225631714\n",
      "Step 1400, Loss: 0.6131659746170044\n",
      "Step 1600, Loss: 0.6127966046333313\n",
      "Step 1800, Loss: 0.6125317811965942\n",
      "Training no hidden layer model with beta=0, n=800, seed=2\n",
      "Step 0, Loss: 0.8349449038505554\n",
      "Step 200, Loss: 0.3633905053138733\n",
      "Step 400, Loss: 0.24890384078025818\n",
      "Step 600, Loss: 0.18756259977817535\n",
      "Step 800, Loss: 0.152544766664505\n",
      "Step 1000, Loss: 0.1318495124578476\n",
      "Step 1200, Loss: 0.11946789175271988\n",
      "Step 1400, Loss: 0.11225906759500504\n",
      "Step 1600, Loss: 0.10847385227680206\n",
      "Step 1800, Loss: 0.10697682946920395\n",
      "Training no hidden layer model with beta=0.017677669529663688, n=800, seed=2\n",
      "Step 0, Loss: 1.1123707294464111\n",
      "Step 200, Loss: 0.628014087677002\n",
      "Step 400, Loss: 0.6223379373550415\n",
      "Step 600, Loss: 0.6209932565689087\n",
      "Step 800, Loss: 0.6202189922332764\n",
      "Step 1000, Loss: 0.6195166110992432\n",
      "Step 1200, Loss: 0.6188936829566956\n",
      "Step 1400, Loss: 0.6183573007583618\n",
      "Step 1600, Loss: 0.6179645657539368\n",
      "Step 1800, Loss: 0.6176928877830505\n",
      "Training no hidden layer model with beta=0, n=800, seed=3\n",
      "Step 0, Loss: 0.7581905126571655\n",
      "Step 200, Loss: 0.35795530676841736\n",
      "Step 400, Loss: 0.24458226561546326\n",
      "Step 600, Loss: 0.18298189342021942\n",
      "Step 800, Loss: 0.14740701019763947\n",
      "Step 1000, Loss: 0.1262723058462143\n",
      "Step 1200, Loss: 0.11360415816307068\n",
      "Step 1400, Loss: 0.10622351616621017\n",
      "Step 1600, Loss: 0.10234730690717697\n",
      "Step 1800, Loss: 0.10081435739994049\n",
      "Training no hidden layer model with beta=0.017677669529663688, n=800, seed=3\n",
      "Step 0, Loss: 1.1076539754867554\n",
      "Step 200, Loss: 0.6344138979911804\n",
      "Step 400, Loss: 0.6275109052658081\n",
      "Step 600, Loss: 0.6256725788116455\n",
      "Step 800, Loss: 0.6246755719184875\n",
      "Step 1000, Loss: 0.6238126754760742\n",
      "Step 1200, Loss: 0.6231745481491089\n",
      "Step 1400, Loss: 0.6226682662963867\n",
      "Step 1600, Loss: 0.6222631931304932\n",
      "Step 1800, Loss: 0.6219973564147949\n",
      "Training no hidden layer model with beta=0, n=800, seed=4\n",
      "Step 0, Loss: 0.7640218138694763\n",
      "Step 200, Loss: 0.3426976799964905\n",
      "Step 400, Loss: 0.22965221107006073\n",
      "Step 600, Loss: 0.17099741101264954\n",
      "Step 800, Loss: 0.1379925012588501\n",
      "Step 1000, Loss: 0.11864610761404037\n",
      "Step 1200, Loss: 0.10713259130716324\n",
      "Step 1400, Loss: 0.10045047849416733\n",
      "Step 1600, Loss: 0.09694749861955643\n",
      "Step 1800, Loss: 0.09556274116039276\n",
      "Training no hidden layer model with beta=0.017677669529663688, n=800, seed=4\n",
      "Step 0, Loss: 1.4642274379730225\n",
      "Step 200, Loss: 0.6241164207458496\n",
      "Step 400, Loss: 0.6116815805435181\n",
      "Step 600, Loss: 0.6081336736679077\n",
      "Step 800, Loss: 0.6061261296272278\n",
      "Step 1000, Loss: 0.6049947738647461\n",
      "Step 1200, Loss: 0.6041485071182251\n",
      "Step 1400, Loss: 0.6034899353981018\n",
      "Step 1600, Loss: 0.6030395030975342\n",
      "Step 1800, Loss: 0.6027655005455017\n",
      "Training no hidden layer model with beta=0, n=1600, seed=0\n",
      "Step 0, Loss: 0.6974731087684631\n",
      "Step 200, Loss: 0.4470992088317871\n",
      "Step 400, Loss: 0.3596276044845581\n",
      "Step 600, Loss: 0.3053445816040039\n",
      "Step 800, Loss: 0.2688305974006653\n",
      "Step 1000, Loss: 0.2437586486339569\n",
      "Step 1200, Loss: 0.22685599327087402\n",
      "Step 1400, Loss: 0.21614128351211548\n",
      "Step 1600, Loss: 0.2102086842060089\n",
      "Step 1800, Loss: 0.20779946446418762\n",
      "Training no hidden layer model with beta=0.0125, n=1600, seed=0\n",
      "Step 0, Loss: 1.1481434106826782\n",
      "Step 200, Loss: 0.6337009072303772\n",
      "Step 400, Loss: 0.6248745322227478\n",
      "Step 600, Loss: 0.6233447194099426\n",
      "Step 800, Loss: 0.6225168704986572\n",
      "Step 1000, Loss: 0.621929407119751\n",
      "Step 1200, Loss: 0.6215067505836487\n",
      "Step 1400, Loss: 0.6211305260658264\n",
      "Step 1600, Loss: 0.6208468079566956\n",
      "Step 1800, Loss: 0.6206746101379395\n",
      "Training no hidden layer model with beta=0, n=1600, seed=1\n",
      "Step 0, Loss: 0.7038474082946777\n",
      "Step 200, Loss: 0.4416792094707489\n",
      "Step 400, Loss: 0.35523948073387146\n",
      "Step 600, Loss: 0.3018723726272583\n",
      "Step 800, Loss: 0.2658827006816864\n",
      "Step 1000, Loss: 0.2411079853773117\n",
      "Step 1200, Loss: 0.22439949214458466\n",
      "Step 1400, Loss: 0.21381902694702148\n",
      "Step 1600, Loss: 0.20796851813793182\n",
      "Step 1800, Loss: 0.20559494197368622\n",
      "Training no hidden layer model with beta=0.0125, n=1600, seed=1\n",
      "Step 0, Loss: 1.052639365196228\n",
      "Step 200, Loss: 0.6302276849746704\n",
      "Step 400, Loss: 0.6204929351806641\n",
      "Step 600, Loss: 0.618364155292511\n",
      "Step 800, Loss: 0.617188572883606\n",
      "Step 1000, Loss: 0.6164827942848206\n",
      "Step 1200, Loss: 0.6159604787826538\n",
      "Step 1400, Loss: 0.6155732870101929\n",
      "Step 1600, Loss: 0.6152711510658264\n",
      "Step 1800, Loss: 0.6150966286659241\n",
      "Training no hidden layer model with beta=0, n=1600, seed=2\n",
      "Step 0, Loss: 0.8312749862670898\n",
      "Step 200, Loss: 0.4547848701477051\n",
      "Step 400, Loss: 0.37228575348854065\n",
      "Step 600, Loss: 0.3192673325538635\n",
      "Step 800, Loss: 0.2828056216239929\n",
      "Step 1000, Loss: 0.2574384808540344\n",
      "Step 1200, Loss: 0.240194633603096\n",
      "Step 1400, Loss: 0.229205921292305\n",
      "Step 1600, Loss: 0.22310206294059753\n",
      "Step 1800, Loss: 0.22061896324157715\n",
      "Training no hidden layer model with beta=0.0125, n=1600, seed=2\n",
      "Step 0, Loss: 0.9983878135681152\n",
      "Step 200, Loss: 0.6286413669586182\n",
      "Step 400, Loss: 0.620572566986084\n",
      "Step 600, Loss: 0.6190066337585449\n",
      "Step 800, Loss: 0.6182265877723694\n",
      "Step 1000, Loss: 0.6176720857620239\n",
      "Step 1200, Loss: 0.6172480583190918\n",
      "Step 1400, Loss: 0.6168903112411499\n",
      "Step 1600, Loss: 0.6166266202926636\n",
      "Step 1800, Loss: 0.6164590716362\n",
      "Training no hidden layer model with beta=0, n=1600, seed=3\n",
      "Step 0, Loss: 0.7636944651603699\n",
      "Step 200, Loss: 0.4590420722961426\n",
      "Step 400, Loss: 0.37586119771003723\n",
      "Step 600, Loss: 0.3217761814594269\n",
      "Step 800, Loss: 0.2841116189956665\n",
      "Step 1000, Loss: 0.25767940282821655\n",
      "Step 1200, Loss: 0.23963843286037445\n",
      "Step 1400, Loss: 0.22812755405902863\n",
      "Step 1600, Loss: 0.22173337638378143\n",
      "Step 1800, Loss: 0.21913307905197144\n",
      "Training no hidden layer model with beta=0.0125, n=1600, seed=3\n",
      "Step 0, Loss: 0.9932327270507812\n",
      "Step 200, Loss: 0.633230447769165\n",
      "Step 400, Loss: 0.6244483590126038\n",
      "Step 600, Loss: 0.6225584149360657\n",
      "Step 800, Loss: 0.6215508580207825\n",
      "Step 1000, Loss: 0.6208915710449219\n",
      "Step 1200, Loss: 0.620412290096283\n",
      "Step 1400, Loss: 0.6200013756752014\n",
      "Step 1600, Loss: 0.6197012662887573\n",
      "Step 1800, Loss: 0.6195225119590759\n",
      "Training no hidden layer model with beta=0, n=1600, seed=4\n",
      "Step 0, Loss: 0.7617294192314148\n",
      "Step 200, Loss: 0.4466935396194458\n",
      "Step 400, Loss: 0.3589687943458557\n",
      "Step 600, Loss: 0.30452847480773926\n",
      "Step 800, Loss: 0.26775312423706055\n",
      "Step 1000, Loss: 0.2424015998840332\n",
      "Step 1200, Loss: 0.22527313232421875\n",
      "Step 1400, Loss: 0.2144080251455307\n",
      "Step 1600, Loss: 0.20839296281337738\n",
      "Step 1800, Loss: 0.20595142245292664\n",
      "Training no hidden layer model with beta=0.0125, n=1600, seed=4\n",
      "Step 0, Loss: 1.3347753286361694\n",
      "Step 200, Loss: 0.634380578994751\n",
      "Step 400, Loss: 0.6219279766082764\n",
      "Step 600, Loss: 0.6201406121253967\n",
      "Step 800, Loss: 0.6191986799240112\n",
      "Step 1000, Loss: 0.618543267250061\n",
      "Step 1200, Loss: 0.6181178092956543\n",
      "Step 1400, Loss: 0.6177756786346436\n",
      "Step 1600, Loss: 0.6175181865692139\n",
      "Step 1800, Loss: 0.6173545718193054\n",
      "Training no hidden layer model with beta=0, n=3200, seed=0\n",
      "Step 0, Loss: 0.697507381439209\n",
      "Step 200, Loss: 0.5093804597854614\n",
      "Step 400, Loss: 0.45294108986854553\n",
      "Step 600, Loss: 0.41681769490242004\n",
      "Step 800, Loss: 0.39155974984169006\n",
      "Step 1000, Loss: 0.3735775351524353\n",
      "Step 1200, Loss: 0.3610681891441345\n",
      "Step 1400, Loss: 0.35293635725975037\n",
      "Step 1600, Loss: 0.348352313041687\n",
      "Step 1800, Loss: 0.34647053480148315\n",
      "Training no hidden layer model with beta=0.008838834764831844, n=3200, seed=0\n",
      "Step 0, Loss: 1.0626137256622314\n",
      "Step 200, Loss: 0.6359314918518066\n",
      "Step 400, Loss: 0.6235309839248657\n",
      "Step 600, Loss: 0.6218596696853638\n",
      "Step 800, Loss: 0.6210638284683228\n",
      "Step 1000, Loss: 0.6205996870994568\n",
      "Step 1200, Loss: 0.6202636957168579\n",
      "Step 1400, Loss: 0.6200181245803833\n",
      "Step 1600, Loss: 0.6198301315307617\n",
      "Step 1800, Loss: 0.6197219491004944\n",
      "Training no hidden layer model with beta=0, n=3200, seed=1\n",
      "Step 0, Loss: 0.7013062834739685\n",
      "Step 200, Loss: 0.501154899597168\n",
      "Step 400, Loss: 0.44614142179489136\n",
      "Step 600, Loss: 0.41076749563217163\n",
      "Step 800, Loss: 0.38603782653808594\n",
      "Step 1000, Loss: 0.3684324622154236\n",
      "Step 1200, Loss: 0.35617491602897644\n",
      "Step 1400, Loss: 0.34819865226745605\n",
      "Step 1600, Loss: 0.3436988890171051\n",
      "Step 1800, Loss: 0.3418508768081665\n",
      "Training no hidden layer model with beta=0.008838834764831844, n=3200, seed=1\n",
      "Step 0, Loss: 0.9648208618164062\n",
      "Step 200, Loss: 0.6270741820335388\n",
      "Step 400, Loss: 0.6148496866226196\n",
      "Step 600, Loss: 0.6128152012825012\n",
      "Step 800, Loss: 0.6119452714920044\n",
      "Step 1000, Loss: 0.6114744544029236\n",
      "Step 1200, Loss: 0.6111267805099487\n",
      "Step 1400, Loss: 0.6108850240707397\n",
      "Step 1600, Loss: 0.6107137203216553\n",
      "Step 1800, Loss: 0.6106069087982178\n",
      "Training no hidden layer model with beta=0, n=3200, seed=2\n",
      "Step 0, Loss: 0.8218269348144531\n",
      "Step 200, Loss: 0.5309767723083496\n",
      "Step 400, Loss: 0.4791307747364044\n",
      "Step 600, Loss: 0.445355623960495\n",
      "Step 800, Loss: 0.4213988482952118\n",
      "Step 1000, Loss: 0.4041443467140198\n",
      "Step 1200, Loss: 0.3920331597328186\n",
      "Step 1400, Loss: 0.38410988450050354\n",
      "Step 1600, Loss: 0.3796251118183136\n",
      "Step 1800, Loss: 0.37777984142303467\n",
      "Training no hidden layer model with beta=0.008838834764831844, n=3200, seed=2\n",
      "Step 0, Loss: 0.9171737432479858\n",
      "Step 200, Loss: 0.6432081460952759\n",
      "Step 400, Loss: 0.6340593099594116\n",
      "Step 600, Loss: 0.6327765583992004\n",
      "Step 800, Loss: 0.6322782635688782\n",
      "Step 1000, Loss: 0.631969690322876\n",
      "Step 1200, Loss: 0.6317048072814941\n",
      "Step 1400, Loss: 0.6315199136734009\n",
      "Step 1600, Loss: 0.6313585042953491\n",
      "Step 1800, Loss: 0.6312602162361145\n",
      "Training no hidden layer model with beta=0, n=3200, seed=3\n",
      "Step 0, Loss: 0.7605365514755249\n",
      "Step 200, Loss: 0.521940290927887\n",
      "Step 400, Loss: 0.46839651465415955\n",
      "Step 600, Loss: 0.4332156181335449\n",
      "Step 800, Loss: 0.4083748161792755\n",
      "Step 1000, Loss: 0.39068570733070374\n",
      "Step 1200, Loss: 0.3784133195877075\n",
      "Step 1400, Loss: 0.3704575002193451\n",
      "Step 1600, Loss: 0.36598140001296997\n",
      "Step 1800, Loss: 0.3641458749771118\n",
      "Training no hidden layer model with beta=0.008838834764831844, n=3200, seed=3\n",
      "Step 0, Loss: 0.9058700203895569\n",
      "Step 200, Loss: 0.6376652121543884\n",
      "Step 400, Loss: 0.627884030342102\n",
      "Step 600, Loss: 0.6263466477394104\n",
      "Step 800, Loss: 0.6257645487785339\n",
      "Step 1000, Loss: 0.6254353523254395\n",
      "Step 1200, Loss: 0.6251627206802368\n",
      "Step 1400, Loss: 0.6249203681945801\n",
      "Step 1600, Loss: 0.6247666478157043\n",
      "Step 1800, Loss: 0.624658465385437\n",
      "Training no hidden layer model with beta=0, n=3200, seed=4\n",
      "Step 0, Loss: 0.7581246495246887\n",
      "Step 200, Loss: 0.5064592957496643\n",
      "Step 400, Loss: 0.45209845900535583\n",
      "Step 600, Loss: 0.41757407784461975\n",
      "Step 800, Loss: 0.39348793029785156\n",
      "Step 1000, Loss: 0.3762824833393097\n",
      "Step 1200, Loss: 0.36425331234931946\n",
      "Step 1400, Loss: 0.3563992977142334\n",
      "Step 1600, Loss: 0.35195857286453247\n",
      "Step 1800, Loss: 0.35013267397880554\n",
      "Training no hidden layer model with beta=0.008838834764831844, n=3200, seed=4\n",
      "Step 0, Loss: 1.2490339279174805\n",
      "Step 200, Loss: 0.6326489448547363\n",
      "Step 400, Loss: 0.6175912618637085\n",
      "Step 600, Loss: 0.6154680848121643\n",
      "Step 800, Loss: 0.6145913004875183\n",
      "Step 1000, Loss: 0.6140851378440857\n",
      "Step 1200, Loss: 0.6137218475341797\n",
      "Step 1400, Loss: 0.6134964227676392\n",
      "Step 1600, Loss: 0.6133244037628174\n",
      "Step 1800, Loss: 0.6132176518440247\n",
      "Training no hidden layer model with beta=0, n=6400, seed=0\n",
      "Step 0, Loss: 0.7012605667114258\n",
      "Step 200, Loss: 0.5577370524406433\n",
      "Step 400, Loss: 0.5262917876243591\n",
      "Step 600, Loss: 0.5061683058738708\n",
      "Step 800, Loss: 0.49224570393562317\n",
      "Step 1000, Loss: 0.4824069142341614\n",
      "Step 1200, Loss: 0.47559526562690735\n",
      "Step 1400, Loss: 0.47118163108825684\n",
      "Step 1600, Loss: 0.468697726726532\n",
      "Step 1800, Loss: 0.46767809987068176\n",
      "Training no hidden layer model with beta=0.00625, n=6400, seed=0\n",
      "Step 0, Loss: 0.9972420930862427\n",
      "Step 200, Loss: 0.6400332450866699\n",
      "Step 400, Loss: 0.625929594039917\n",
      "Step 600, Loss: 0.6237459182739258\n",
      "Step 800, Loss: 0.6230475902557373\n",
      "Step 1000, Loss: 0.6226667165756226\n",
      "Step 1200, Loss: 0.6224398612976074\n",
      "Step 1400, Loss: 0.6222660541534424\n",
      "Step 1600, Loss: 0.6221488118171692\n",
      "Step 1800, Loss: 0.6220811605453491\n",
      "Training no hidden layer model with beta=0, n=6400, seed=1\n",
      "Step 0, Loss: 0.7007896900177002\n",
      "Step 200, Loss: 0.5490556955337524\n",
      "Step 400, Loss: 0.5153460502624512\n",
      "Step 600, Loss: 0.49412503838539124\n",
      "Step 800, Loss: 0.4794158339500427\n",
      "Step 1000, Loss: 0.46902379393577576\n",
      "Step 1200, Loss: 0.4618445932865143\n",
      "Step 1400, Loss: 0.45720311999320984\n",
      "Step 1600, Loss: 0.4545954763889313\n",
      "Step 1800, Loss: 0.4535260796546936\n",
      "Training no hidden layer model with beta=0.00625, n=6400, seed=1\n",
      "Step 0, Loss: 0.8973610401153564\n",
      "Step 200, Loss: 0.6349233388900757\n",
      "Step 400, Loss: 0.6210920810699463\n",
      "Step 600, Loss: 0.618874192237854\n",
      "Step 800, Loss: 0.6180498600006104\n",
      "Step 1000, Loss: 0.6176254153251648\n",
      "Step 1200, Loss: 0.6173162460327148\n",
      "Step 1400, Loss: 0.6171448230743408\n",
      "Step 1600, Loss: 0.617012083530426\n",
      "Step 1800, Loss: 0.6169382333755493\n",
      "Training no hidden layer model with beta=0, n=6400, seed=2\n",
      "Step 0, Loss: 0.8242469429969788\n",
      "Step 200, Loss: 0.5603163838386536\n",
      "Step 400, Loss: 0.527813732624054\n",
      "Step 600, Loss: 0.5079731345176697\n",
      "Step 800, Loss: 0.4943266212940216\n",
      "Step 1000, Loss: 0.48464012145996094\n",
      "Step 1200, Loss: 0.4779003858566284\n",
      "Step 1400, Loss: 0.47351688146591187\n",
      "Step 1600, Loss: 0.47104406356811523\n",
      "Step 1800, Loss: 0.47002771496772766\n",
      "Training no hidden layer model with beta=0.00625, n=6400, seed=2\n",
      "Step 0, Loss: 0.8588571548461914\n",
      "Step 200, Loss: 0.6397517323493958\n",
      "Step 400, Loss: 0.6277452707290649\n",
      "Step 600, Loss: 0.6257214546203613\n",
      "Step 800, Loss: 0.6249603033065796\n",
      "Step 1000, Loss: 0.6245537996292114\n",
      "Step 1200, Loss: 0.6242707371711731\n",
      "Step 1400, Loss: 0.62408047914505\n",
      "Step 1600, Loss: 0.6239549517631531\n",
      "Step 1800, Loss: 0.6238789558410645\n",
      "Training no hidden layer model with beta=0, n=6400, seed=3\n",
      "Step 0, Loss: 0.7636133432388306\n",
      "Step 200, Loss: 0.5571281909942627\n",
      "Step 400, Loss: 0.5249785780906677\n",
      "Step 600, Loss: 0.5041675567626953\n",
      "Step 800, Loss: 0.48965543508529663\n",
      "Step 1000, Loss: 0.4794401526451111\n",
      "Step 1200, Loss: 0.4724191129207611\n",
      "Step 1400, Loss: 0.4678981304168701\n",
      "Step 1600, Loss: 0.4653643071651459\n",
      "Step 1800, Loss: 0.46432632207870483\n",
      "Training no hidden layer model with beta=0.00625, n=6400, seed=3\n",
      "Step 0, Loss: 0.8446981310844421\n",
      "Step 200, Loss: 0.63492351770401\n",
      "Step 400, Loss: 0.6229313611984253\n",
      "Step 600, Loss: 0.6208208203315735\n",
      "Step 800, Loss: 0.6200409531593323\n",
      "Step 1000, Loss: 0.619647204875946\n",
      "Step 1200, Loss: 0.6193796992301941\n",
      "Step 1400, Loss: 0.6192063093185425\n",
      "Step 1600, Loss: 0.6190822124481201\n",
      "Step 1800, Loss: 0.619010329246521\n",
      "Training no hidden layer model with beta=0, n=6400, seed=4\n",
      "Step 0, Loss: 0.7711265683174133\n",
      "Step 200, Loss: 0.5543034076690674\n",
      "Step 400, Loss: 0.5219945907592773\n",
      "Step 600, Loss: 0.501744270324707\n",
      "Step 800, Loss: 0.48774847388267517\n",
      "Step 1000, Loss: 0.47786635160446167\n",
      "Step 1200, Loss: 0.47104161977767944\n",
      "Step 1400, Loss: 0.46663206815719604\n",
      "Step 1600, Loss: 0.4641560912132263\n",
      "Step 1800, Loss: 0.4631411135196686\n",
      "Training no hidden layer model with beta=0.00625, n=6400, seed=4\n",
      "Step 0, Loss: 1.182971715927124\n",
      "Step 200, Loss: 0.640041172504425\n",
      "Step 400, Loss: 0.6229716539382935\n",
      "Step 600, Loss: 0.619962751865387\n",
      "Step 800, Loss: 0.6189804077148438\n",
      "Step 1000, Loss: 0.6184114217758179\n",
      "Step 1200, Loss: 0.6180782914161682\n",
      "Step 1400, Loss: 0.6178710460662842\n",
      "Step 1600, Loss: 0.6177363395690918\n",
      "Step 1800, Loss: 0.6176602840423584\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "_, d = diff_features.shape\n",
    "lr = 1e-3\n",
    "wd = 1e-2\n",
    "steps = int(2e3)\n",
    "rate = 1\n",
    "lr_nohidden = lr\n",
    "n_list = [200, 400, 800, 1600, 3200, 6400]\n",
    "num_repeats = 5 \n",
    "\n",
    "results = {\n",
    "    \"n\": [],\n",
    "    \"seed\": [],\n",
    "    \"beta\": [],\n",
    "    \"acc_train\": [],\n",
    "    \"acc_eval\": [],\n",
    "    \"sparsity\": [],\n",
    "    \"sparsity_rough\": []\n",
    "}\n",
    "\n",
    "for n in n_list:\n",
    "    for seed in range(num_repeats):  \n",
    "        torch.manual_seed(seed)  \n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        np.random.seed(seed)\n",
    "\n",
    "        diff_features_subset = diff_features[torch.randperm(n_samples)[:n], :]\n",
    "        \n",
    "        for beta in [0, 0.5 * (1 / np.sqrt(n))]:  \n",
    "            print(f\"Training no hidden layer model with beta={beta}, n={n}, seed={seed}\")\n",
    "\n",
    "            model_no_hidden = NeuralNetworkNoHidden(input_size=d).to(device)\n",
    "            optimizer = AdamW(model_no_hidden.parameters(), lr=lr_nohidden, weight_decay=wd)\n",
    "            scheduler = CosineAnnealingLR(optimizer, T_max=steps)\n",
    "\n",
    "            model_no_hidden, acc_train_no_hidden, loss_history_no_hidden = train_neural_network_no_hidden(\n",
    "                model_no_hidden, optimizer, scheduler, diff_features_subset, beta=beta, steps=steps, seed=seed\n",
    "            )\n",
    "            acc_eval_no_hidden = (model_no_hidden(diff_features_eval) > 0).float().mean()\n",
    "            sparsity_no_hidden = (model_no_hidden.outputlayer.weight != 0).float().mean()\n",
    "            sparsity_no_hidden_rough = (model_no_hidden.outputlayer.weight.abs() > 1e-6).float().mean()\n",
    "\n",
    "            results[\"n\"].append(n)\n",
    "            results[\"seed\"].append(seed)\n",
    "            results[\"beta\"].append(beta)\n",
    "            results[\"acc_train\"].append(acc_train_no_hidden)\n",
    "            results[\"acc_eval\"].append(acc_eval_no_hidden)\n",
    "            results[\"sparsity\"].append(sparsity_no_hidden)\n",
    "            results[\"sparsity_rough\"].append(sparsity_no_hidden_rough)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x250 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "results_cpu = {\n",
    "    key: [x.cpu().item() if torch.is_tensor(x) else x for x in values]\n",
    "    for key, values in results.items()\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(results_cpu)\n",
    "df1 = df.copy()\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['font.family'] = 'DejaVu Serif'\n",
    "df[\"beta_category\"] = df[\"beta\"].apply(lambda x: \"β=0\" if x == 0 else \"β>0\")\n",
    "df[\"beta_category\"] = df[\"beta_category\"].replace({\n",
    "    \"β=0\": r\"$\\beta = 0$\",  \n",
    "    \"β>0\": r\"$\\ell_{1}$-regularized\"  \n",
    "})\n",
    "df[\"acc_eval\"] = df[\"acc_eval\"].apply(lambda x: x.cpu().item() * 100 if torch.is_tensor(x) else x * 100)\n",
    "\n",
    "df_summary = df.groupby([\"n\", \"beta_category\"]).agg(\n",
    "    acc_eval_mean=(\"acc_eval\", \"mean\")\n",
    ").reset_index()\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "plt.rcParams[\"font.family\"] = \"DejaVu Serif\"  \n",
    "plt.rcParams[\"mathtext.fontset\"] = \"stix\"  \n",
    "\n",
    "df = df[df[\"n\"] >= 200]\n",
    "plt.figure(figsize=(4, 2.5))\n",
    "sns.lineplot(data=df, x=\"n\", y=\"acc_eval\", hue=\"beta_category\")\n",
    "\n",
    "plt.xscale(\"log\")\n",
    "plt.xlabel(\"$n$ (log scale)\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "\n",
    "x_ticks = df[\"n\"].unique()  \n",
    "plt.xticks(x_ticks, labels=[str(n) for n in x_ticks])  \n",
    "\n",
    "y_min, y_max = df[\"acc_eval\"].min(), df[\"acc_eval\"].max()\n",
    "y_ticks = np.linspace(y_min, y_max, num=10)  \n",
    "\n",
    "\n",
    "plt.xlim(200, 6400) \n",
    "plt.legend(title=None)\n",
    "plt.savefig('last_1B_SHP_0d5.pdf', format='pdf', bbox_inches='tight')\n",
    "\n",
    "plt.show()\n",
    "df1.to_json(\"SHP_results_1B_0d5.json\", orient=\"records\", indent=4)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
